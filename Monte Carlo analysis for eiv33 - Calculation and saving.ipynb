{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import os               # to use \"operating system dependent functionality\"\n",
    "import numpy as np      # \"the fundamental package for scientific computing with Python\"\n",
    "import pandas as pd     # \"high-performance, easy-to-use data structures and data analysis tools\" for Python\n",
    "import csv\n",
    "import stats_arrays\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bw.projects.set_current('iw_integration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load functions with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_save(file_path_root,object_name_to_save,file_name):\n",
    "    \n",
    "    complete_file_path=file_path_root+'\\\\'+file_name+'.p'\n",
    "    \n",
    "    pickle.dump( object_name_to_save, open( complete_file_path, \"wb\" ) )\n",
    "    \n",
    "    return;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pickle_load(file_path_root,file_name):\n",
    "    \n",
    "    complete_file_path=file_path_root+'\\\\'+file_name+'.p'\n",
    "    \n",
    "    return pickle.load( open( complete_file_path, \"rb\" ) );\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "#object_name_to_save=object_to_save\n",
    "#file_name='object_to_save'\n",
    "\n",
    "pickle_save(file_path_root,object_name_to_save,file_name)\n",
    "\n",
    "object_to_load=pickle_load(file_path_root,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load LCA object for an activity in eiv33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a random process in eiv33 and construct an LCA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_eiv33=bw.Database('ecoinvent 3.3 cutoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act_random_eiv33=DB_eiv33.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_LCA_object(act,fu,ic_name=None):\n",
    "    LCA_object=bw.LCA({act:fu},ic_name)\n",
    "    return LCA_object;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act=act_random_eiv33\n",
    "fu=1\n",
    "\n",
    "LCA_object=create_LCA_object(act,fu,ic_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create A and B matrices with .load_lci_data() and save the resulting objects with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_A_B(LCA_obj,params_only=False, matrix_only=False):\n",
    "    LCA_obj.load_lci_data(fix_dictionaries=False)\n",
    "    dict_load_lci_data_objects={}\n",
    "    \n",
    "    if params_only==True:\n",
    "        dict_load_lci_data_objects={'bio_params':LCA_obj.bio_params,\n",
    "                               'tech_params':LCA_obj.tech_params}\n",
    "    elif matrix_only==True:\n",
    "        dict_load_lci_data_objects={'biosphere_matrix':LCA_obj.biosphere_matrix,\n",
    "                               'technosphere_matrix':LCA_obj.technosphere_matrix}\n",
    "    \n",
    "    else:\n",
    "        dict_load_lci_data_objects={'bio_params':LCA_obj.bio_params,\n",
    "                               'tech_params':LCA_obj.tech_params,\n",
    "                               'biosphere_dict':LCA_obj.biosphere_dict,\n",
    "                               'activity_dict':LCA_obj.activity_dict,\n",
    "                               'product_dict':LCA_obj.product_dict,\n",
    "                               'biosphere_matrix':LCA_obj.biosphere_matrix,\n",
    "                               'technosphere_matrix':LCA_obj.technosphere_matrix}\n",
    "    \n",
    "    return dict_load_lci_data_objects;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_A_B=create_A_B(LCA_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "object_name_to_save=dict_A_B\n",
    "file_name='dict_A_B_random_eiv33'\n",
    "\n",
    "pickle_save(file_path_root,object_name_to_save,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the LCA object and finish the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "object_name_to_save=dict_A_B\n",
    "file_name='dict_A_B_random_eiv33'\n",
    "\n",
    "dict_A_B_load=pickle_load(file_path_root,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_A_B_to_LCA_object(dict_A_B,act,fu,ic_name=None):\n",
    "    \n",
    "    LCA_obj=create_LCA_object(act,fu,ic_name)\n",
    "    \n",
    "    #This function recreates the objects created during the .load_lci_data()\n",
    "    \n",
    "    #to replace builder.build(self.database_filepath) in .load_lci_data()\n",
    "    LCA_obj.bio_params=dict_A_B['bio_params']\n",
    "    LCA_obj.tech_params=dict_A_B['tech_params']\n",
    "    LCA_obj.biosphere_dict=dict_A_B['biosphere_dict']\n",
    "    LCA_obj.activity_dict=dict_A_B['activity_dict']\n",
    "    LCA_obj.product_dict=dict_A_B['product_dict']\n",
    "    LCA_obj.biosphere_matrix=dict_A_B['biosphere_matrix']\n",
    "    LCA_obj.technosphere_matrix=dict_A_B['technosphere_matrix']\n",
    "\n",
    "    LCA_obj.fix_dictionaries() #function in .load_lci_data()\n",
    "    \n",
    "    return LCA_obj;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_name=('IMPACTWorld+ - Endpoint - only with spatial variability - Four param beta integration - update august 15th 2017','Ecosystem Quality','Land transformation, biodiversity, GLO, with uncert')\n",
    "\n",
    "LCA_object_load=load_A_B_to_LCA_object(dict_A_B_load,act,fu,ic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finish_LCA_object(LCA_obj):\n",
    "\n",
    "    #The beginning of .lci() function replace by the load_A_B_to_LCA_object function\n",
    "    \n",
    "    LCA_obj.build_demand_array() #function in .lci() after calling .load_lci_data()\n",
    "    LCA_obj.lci_calculation() #function in .lci() after calling .load_lci_data()\n",
    "    LCA_obj.lcia()\n",
    "    \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_LCA_object(LCA_object_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00032472068199512565"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCA_object_load.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all created objects in LCA object to test if everything needs to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_random_eiv33_1=DB_eiv33.random()\n",
    "act_random_eiv33_2=DB_eiv33.random()\n",
    "act_1=act_random_eiv33_2\n",
    "act_2=act_random_eiv33_2\n",
    "fu=1\n",
    "\n",
    "LCA_object_1=create_LCA_object(act_1,fu,ic_name=None)\n",
    "LCA_object_2=create_LCA_object(act_2,fu,ic_name=None)\n",
    "dict_A_B_1=create_A_B(LCA_object_1)\n",
    "dict_A_B_2=create_A_B(LCA_object_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True, ...,  True,  True,  True], dtype=bool),\n",
       " array([ True,  True,  True, ...,  True,  True,  True], dtype=bool),\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " <1960x13831 sparse matrix of type '<class 'numpy.bool_'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " <13831x13831 sparse matrix of type '<class 'numpy.bool_'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dict_A_B_1['bio_params']!=dict_A_B_2['bio_params'],\n",
    " dict_A_B_1['tech_params']!=dict_A_B_2['tech_params'],\n",
    " dict_A_B_1['biosphere_dict']!=dict_A_B_2['biosphere_dict'],\n",
    " dict_A_B_1['activity_dict']!=dict_A_B_2['activity_dict'],\n",
    " dict_A_B_1['product_dict']!=dict_A_B_2['product_dict'],\n",
    " dict_A_B_1['biosphere_matrix']!=dict_A_B_2['biosphere_matrix'],\n",
    " dict_A_B_1['technosphere_matrix']!=dict_A_B_2['technosphere_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosphere_mat_comparison=LCA_object_1.biosphere_matrix.data!=LCA_object_2.biosphere_matrix.data\n",
    "technosphere_mat_comparison=LCA_object_1.technosphere_matrix.data!=LCA_object_2.technosphere_matrix.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in biosphere_mat_comparison:\n",
    "    if comp==True:\n",
    "        print('biosphere matrices are different')\n",
    "        \n",
    "for comp in technosphere_mat_comparison:\n",
    "    if comp==True:\n",
    "        print('biosphere matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only bio_params and tech_params need to be stored, the other are the same for all activities in eiv33! \n",
    "--> around 20MB instead of 30MB for all the objects per activity per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "object_name_to_save=dict_A_B_1['bio_params']\n",
    "file_name='dict_A_B_1_bio_params'\n",
    "\n",
    "pickle_save(file_path_root,object_name_to_save,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "object_name_to_save=dict_A_B_1['tech_params']\n",
    "file_name='dict_A_B_1_tech_params'\n",
    "\n",
    "pickle_save(file_path_root,object_name_to_save,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a code to only generate bio_params and tech_params? Ça l'air compliqué..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo for LCI for an activity + storage as dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About objects needed to recreate an LCA object:\n",
    "-*biosphere_dict, activity_dict, product_dict* are the same for the entire DB\n",
    "-*bio_params, tech_params* remain the same for an activity whatever the MC iteration\n",
    "-*biosphere_matrix, technosphere_matrix* change for every MC iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_eiv33=bw.Database('ecoinvent 3.3 cutoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "act=DB_eiv33.random()\n",
    "fu=1\n",
    "iterations=10\n",
    "matrix_only=True\n",
    "\n",
    "LCA_obj=create_LCA_object(act,fu,ic_name=None)\n",
    "dict_A_B=create_A_B(LCA_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity': '64fbcf36-d909-4f9f-bc95-d4f8302a554e',\n",
       " 'activity type': 'ordinary transforming activity',\n",
       " 'authors': {'data entry': {'email': 'support@ecoinvent.org',\n",
       "   'name': '[System]'},\n",
       "  'data generator': {'email': 'empa@ecoinvent.org',\n",
       "   'name': 'Daniel Kellenberger (obsolete)'}},\n",
       " 'classifications': [('EcoSpold01Categories',\n",
       "   'construction materials/additives'),\n",
       "  ('ISIC rev.4 ecoinvent', '0810:Quarrying of stone, sand and clay')],\n",
       " 'code': '19bc3a0ced0cab3b62cc6f08331a53dd',\n",
       " 'comment': 'This dataset represents the production of 1 kg of clay in a mine, assuming a thickness of the clay layer in nature of 30m. Different types of transformation in Europe, therefore \"transformation, to unknown\" has been chosen.\\nClay pit. Image source: https://commons.wikimedia.org/wiki/File:Mettingen_Querenberg_Clay_Pit_02.jpg, accessed 20151211\\nImage: https://db3.ecoinvent.org/images/22ca9d18-ea16-410c-86f8-c5aa370920c7\\nGeography:  \"recultivation, bauxite mine\" has been used as Proxy\\nTechnology:  typical technology for swiss clay mining',\n",
       " 'database': 'ecoinvent 3.3 cutoff',\n",
       " 'filename': '64fbcf36-d909-4f9f-bc95-d4f8302a554e_e89b4064-afcc-4f08-9481-651b7eaa90a1.spold',\n",
       " 'flow': 'e89b4064-afcc-4f08-9481-651b7eaa90a1',\n",
       " 'location': 'RoW',\n",
       " 'name': 'clay pit operation',\n",
       " 'parameters': {},\n",
       " 'production amount': 1.0,\n",
       " 'reference product': 'clay',\n",
       " 'type': 'process',\n",
       " 'unit': 'kilogram'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LCI_MonteCarlo_from_LCA_object(act,fu,LCA_obj,iterations,matrix_only=True,seed=None):\n",
    "    \n",
    "    LCA_obj.fix_dictionaries()\n",
    "    \n",
    "    dict_act_MC_LCA_object={}\n",
    "    dict_act_MC_LCA_object['iterations']=iterations\n",
    "    dict_act_MC_LCA_object['activity key']=act.key\n",
    "    dict_act_MC_LCA_object['classifications']=act.as_dict()['classifications']\n",
    "    dict_act_MC_LCA_object['functional unit']=fu\n",
    "    dict_act_MC_LCA_object['bio_params']=LCA_obj.bio_params\n",
    "    dict_act_MC_LCA_object['tech_params']=LCA_obj.tech_params\n",
    "    dict_act_MC_LCA_object['Monte Carlo LCI results']={} \n",
    "    \n",
    "    \n",
    "    LCA_obj.tech_rng = stats_arrays.random.MCRandomNumberGenerator(LCA_obj.tech_params, seed=seed)\n",
    "    LCA_obj.bio_rng = stats_arrays.random.MCRandomNumberGenerator(LCA_obj.bio_params, seed=seed)\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        LCA_obj.rebuild_technosphere_matrix(LCA_obj.tech_rng.next())\n",
    "        LCA_obj.rebuild_biosphere_matrix(LCA_obj.bio_rng.next())\n",
    "        \n",
    "        dict_act_MC_LCA_object['Monte Carlo LCI results'][it]=create_A_B(LCA_obj,matrix_only=matrix_only)\n",
    "        \n",
    "    return dict_act_MC_LCA_object;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bw2calc.utils import extract_uncertainty_fields as euf\n",
    "\n",
    "def LCI_MonteCarlo_from_LCA_object_params(act,fu,LCA_obj,iterations,matrix_only=True,seed=None):\n",
    "    \n",
    "    LCA_obj.fix_dictionaries()\n",
    "    \n",
    "    dict_act_MC_LCA_object={}\n",
    "    dict_act_MC_LCA_object['iterations']=iterations\n",
    "    dict_act_MC_LCA_object['activity key']=act.key\n",
    "    dict_act_MC_LCA_object['classifications']=act.as_dict()['classifications']\n",
    "    dict_act_MC_LCA_object['functional unit']=fu\n",
    "    dict_act_MC_LCA_object['bio_params']=LCA_obj.bio_params\n",
    "    dict_act_MC_LCA_object['tech_params']=LCA_obj.tech_params\n",
    "    dict_act_MC_LCA_object['Monte Carlo LCI results']={}\n",
    "    dict_act_MC_LCA_object['LCI params values']={}\n",
    "    \n",
    "    \n",
    "    # In order to store LCI parameters values at each iteration\n",
    "    # useful for sensitivity analysis (Inspired from class ParameterVectorLCA)\n",
    "    positions = {\n",
    "    \"tech\": (0, LCA_obj.tech_params.shape[0]),\n",
    "    \"bio\": (\n",
    "        LCA_obj.tech_params.shape[0],\n",
    "        LCA_obj.tech_params.shape[0] + LCA_obj.bio_params.shape[0]\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # `euf` is extract_uncertainty_fields; needed because we are\n",
    "    # \"gluing\" together arrays with different column numbers and labels\n",
    "    params = (euf(LCA_obj.tech_params), euf(LCA_obj.bio_params))\n",
    "    \n",
    "    LCA_obj.positions = positions\n",
    "    LCA_obj.params = np.hstack(params)\n",
    "    LCA_obj.rng = stats_arrays.random.MCRandomNumberGenerator(LCA_obj.params, seed=seed)\n",
    "    \n",
    "    \n",
    "    #LCA_obj.tech_rng = stats_arrays.random.MCRandomNumberGenerator(LCA_obj.tech_params, seed=seed)\n",
    "    #LCA_obj.bio_rng = stats_arrays.random.MCRandomNumberGenerator(LCA_obj.bio_params, seed=seed)\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        \n",
    "        LCA_obj.sample = (LCA_obj.rng.next()).copy()\n",
    "        LCA_obj.tech_sample=LCA_obj.sample[LCA_obj.positions[\"tech\"][0]:LCA_obj.positions[\"tech\"][1]]\n",
    "        LCA_obj.bio_sample=LCA_obj.sample[LCA_obj.positions[\"bio\"][0]:LCA_obj.positions[\"bio\"][1]]     \n",
    "        \n",
    "        LCA_obj.rebuild_technosphere_matrix(LCA_obj.tech_sample)\n",
    "        LCA_obj.rebuild_biosphere_matrix(LCA_obj.bio_sample)\n",
    "        \n",
    "        dict_act_MC_LCA_object['Monte Carlo LCI results'][it]=create_A_B(LCA_obj,matrix_only=matrix_only)\n",
    "        dict_act_MC_LCA_object['LCI params values'][it]={'tech_sample':LCA_obj.tech_sample,'bio_sample':LCA_obj.bio_sample}\n",
    "        \n",
    "    return dict_act_MC_LCA_object;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_act_MC_LCA_object=LCI_MonteCarlo_from_LCA_object(act,fu,LCA_obj,iterations,matrix_only,seed=None)\n",
    "dict_act_MC_LCA_object_params=LCI_MonteCarlo_from_LCA_object_params(act,fu,LCA_obj,iterations,matrix_only,seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "object_name_to_save=dict_act_MC_LCA_object\n",
    "file_name='dict_act_MC_LCA_object_matrix_only'\n",
    "\n",
    "pickle_save(file_path_root,object_name_to_save,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Monte Carlo LCI results': {0: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  1: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  2: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  3: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  4: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  5: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  6: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  7: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  8: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  9: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>}},\n",
       " 'activity key': ('ecoinvent 3.3 cutoff', '19bc3a0ced0cab3b62cc6f08331a53dd'),\n",
       " 'bio_params': array([ (1, 5016, 0, 57, 2, 2, 6.147401290945709e-05, -9.696895599365234, 0.2849561274051666, nan, nan, nan, False),\n",
       "        (1, 5029, 0, 70, 2, 2, 4.9902801038115285e-06, -12.20801830291748, 0.24617066979408264, nan, nan, nan, False),\n",
       "        (1, 5100, 0, 141, 2, 2, 2.768790068330418e-07, -15.099685668945312, 0.057445626705884933, nan, nan, nan, False),\n",
       "        ...,\n",
       "        (4026, 18773, 1958, 13814, 2, 2, 0.00018002913566306233, -8.622391700744629, 0.5744562745094299, nan, nan, nan, False),\n",
       "        (4029, 14719, 1959, 9760, 2, 2, 0.003420199966058135, -5.678056240081787, 0.4669046998023987, nan, nan, nan, False),\n",
       "        (4029, 16287, 1959, 11328, 2, 2, 0.003420199966058135, -5.678056240081787, 0.4669046998023987, nan, nan, nan, False)], \n",
       "       dtype=[('input', '<u4'), ('output', '<u4'), ('row', '<u4'), ('col', '<u4'), ('type', 'u1'), ('uncertainty_type', 'u1'), ('amount', '<f4'), ('loc', '<f4'), ('scale', '<f4'), ('shape', '<f4'), ('minimum', '<f4'), ('maximum', '<f4'), ('negative', '?')]),\n",
       " 'classifications': [('EcoSpold01Categories',\n",
       "   'construction materials/additives'),\n",
       "  ('ISIC rev.4 ecoinvent', '0810:Quarrying of stone, sand and clay')],\n",
       " 'functional unit': 1,\n",
       " 'iterations': 10,\n",
       " 'tech_params': array([(4959, 4959, 0, 0, 0, 0, 1.0, 1.0, nan, nan, nan, nan, False),\n",
       "        (4960, 4960, 1, 1, 0, 0, 1.0, 1.0, nan, nan, nan, nan, False),\n",
       "        (4961, 4961, 2, 2, 0, 0, 1.0, 1.0, nan, nan, nan, nan, False), ...,\n",
       "        (18787, 5952, 13828, 993, 1, 0, -0.9990108609199524, -0.9990108609199524, nan, nan, nan, nan, True),\n",
       "        (18788, 6582, 13829, 1623, 1, 0, 0.9506279826164246, 0.9506279826164246, nan, nan, nan, nan, False),\n",
       "        (18789, 9217, 13830, 4258, 1, 0, 0.9915831089019775, 0.9915831089019775, nan, nan, nan, nan, False)], \n",
       "       dtype=[('input', '<u4'), ('output', '<u4'), ('row', '<u4'), ('col', '<u4'), ('type', 'u1'), ('uncertainty_type', 'u1'), ('amount', '<f4'), ('loc', '<f4'), ('scale', '<f4'), ('shape', '<f4'), ('minimum', '<f4'), ('maximum', '<f4'), ('negative', '?')])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_act_MC_LCA_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LCI params values': {0: {'bio_sample': array([  7.63141373e-05,   5.15439964e-06,   2.49464885e-07, ...,\n",
       "            2.60212256e-04,   3.80671574e-03,   2.29849717e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  1: {'bio_sample': array([  6.79422708e-05,   1.14257832e-05,   2.83163093e-07, ...,\n",
       "            2.54118873e-04,   1.07203393e-02,   3.14829236e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  2: {'bio_sample': array([  7.18973818e-05,   4.17993140e-06,   2.71671575e-07, ...,\n",
       "            2.11089599e-04,   2.99936148e-03,   4.23746800e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  3: {'bio_sample': array([  5.69166665e-05,   4.45519310e-06,   2.92442692e-07, ...,\n",
       "            3.16811853e-04,   3.00643142e-03,   6.71382528e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  4: {'bio_sample': array([  5.23281212e-05,   5.76607949e-06,   2.63653837e-07, ...,\n",
       "            2.55696660e-04,   8.42467104e-03,   3.59016515e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  5: {'bio_sample': array([  9.43553027e-05,   4.79637816e-06,   3.01531848e-07, ...,\n",
       "            1.15271069e-04,   3.05023334e-03,   4.37852296e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  6: {'bio_sample': array([  7.94413539e-05,   3.84371813e-06,   2.70402234e-07, ...,\n",
       "            5.04448016e-05,   4.39199267e-03,   2.40419864e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  7: {'bio_sample': array([  7.72384440e-05,   6.84477711e-06,   2.83209741e-07, ...,\n",
       "            3.48546469e-04,   4.28581015e-03,   3.30698795e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  8: {'bio_sample': array([  1.08618040e-04,   6.09756656e-06,   2.70244380e-07, ...,\n",
       "            2.94526443e-04,   3.13481838e-03,   3.27493938e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])},\n",
       "  9: {'bio_sample': array([  6.54019550e-05,   5.98372645e-06,   2.55114984e-07, ...,\n",
       "            1.73239936e-04,   2.48645760e-03,   3.91377195e-03]),\n",
       "   'tech_sample': array([ 1.        ,  1.        ,  1.        , ..., -0.99901086,\n",
       "           0.95062798,  0.99158311])}},\n",
       " 'Monte Carlo LCI results': {0: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  1: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  2: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  3: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  4: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  5: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  6: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  7: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  8: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>},\n",
       "  9: {'biosphere_matrix': <1960x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 353369 stored elements in Compressed Sparse Row format>,\n",
       "   'technosphere_matrix': <13831x13831 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 147427 stored elements in Compressed Sparse Row format>}},\n",
       " 'activity key': ('ecoinvent 3.3 cutoff', '19bc3a0ced0cab3b62cc6f08331a53dd'),\n",
       " 'bio_params': array([ (1, 5016, 0, 57, 2, 2, 6.147401290945709e-05, -9.696895599365234, 0.2849561274051666, nan, nan, nan, False),\n",
       "        (1, 5029, 0, 70, 2, 2, 4.9902801038115285e-06, -12.20801830291748, 0.24617066979408264, nan, nan, nan, False),\n",
       "        (1, 5100, 0, 141, 2, 2, 2.768790068330418e-07, -15.099685668945312, 0.057445626705884933, nan, nan, nan, False),\n",
       "        ...,\n",
       "        (4026, 18773, 1958, 13814, 2, 2, 0.00018002913566306233, -8.622391700744629, 0.5744562745094299, nan, nan, nan, False),\n",
       "        (4029, 14719, 1959, 9760, 2, 2, 0.003420199966058135, -5.678056240081787, 0.4669046998023987, nan, nan, nan, False),\n",
       "        (4029, 16287, 1959, 11328, 2, 2, 0.003420199966058135, -5.678056240081787, 0.4669046998023987, nan, nan, nan, False)], \n",
       "       dtype=[('input', '<u4'), ('output', '<u4'), ('row', '<u4'), ('col', '<u4'), ('type', 'u1'), ('uncertainty_type', 'u1'), ('amount', '<f4'), ('loc', '<f4'), ('scale', '<f4'), ('shape', '<f4'), ('minimum', '<f4'), ('maximum', '<f4'), ('negative', '?')]),\n",
       " 'classifications': [('EcoSpold01Categories',\n",
       "   'construction materials/additives'),\n",
       "  ('ISIC rev.4 ecoinvent', '0810:Quarrying of stone, sand and clay')],\n",
       " 'functional unit': 1,\n",
       " 'iterations': 10,\n",
       " 'tech_params': array([(4959, 4959, 0, 0, 0, 0, 1.0, 1.0, nan, nan, nan, nan, False),\n",
       "        (4960, 4960, 1, 1, 0, 0, 1.0, 1.0, nan, nan, nan, nan, False),\n",
       "        (4961, 4961, 2, 2, 0, 0, 1.0, 1.0, nan, nan, nan, nan, False), ...,\n",
       "        (18787, 5952, 13828, 993, 1, 0, -0.9990108609199524, -0.9990108609199524, nan, nan, nan, nan, True),\n",
       "        (18788, 6582, 13829, 1623, 1, 0, 0.9506279826164246, 0.9506279826164246, nan, nan, nan, nan, False),\n",
       "        (18789, 9217, 13830, 4258, 1, 0, 0.9915831089019775, 0.9915831089019775, nan, nan, nan, nan, False)], \n",
       "       dtype=[('input', '<u4'), ('output', '<u4'), ('row', '<u4'), ('col', '<u4'), ('type', 'u1'), ('uncertainty_type', 'u1'), ('amount', '<f4'), ('loc', '<f4'), ('scale', '<f4'), ('shape', '<f4'), ('minimum', '<f4'), ('maximum', '<f4'), ('negative', '?')])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_act_MC_LCA_object_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\bw2-python\\Notebook - tutorial\\IW+ integration\\Pickle Python object saved'\n",
    "object_name_to_save=dict_act_MC_LCA_object\n",
    "file_name='dict_act_MC_LCA_object_matrix_only'\n",
    "\n",
    "dict_act_MC_LCA_object_load=pickle_load(file_path_root,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Storage using big data package "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 format: http://deusyss.developpez.com/tutoriels/Python/hdf5/\n",
    "\n",
    "\n",
    "Same size in MB than with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 000 données modifiées en 3.2879414558410645 secondes\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Création d'une matrice\n",
    "mon_tableau = np.ones((10000, 10000))\n",
    "\n",
    "# création du fichier hdf5\n",
    "mon_fichier = h5py.File(r'C:\\Users\\Laure\\Brightway - Notebook\\Notebook - tutorial\\IW+ integration\\HDF5 object saved\\mon_fichier.hdf5', 'a')\n",
    "mon_dataset = mon_fichier.create_dataset(\"fichier de demo2\", data=mon_tableau)\n",
    "mon_fichier.flush()\n",
    "\n",
    "# Maintenant les données numériques sont aisément accessible\n",
    "start = time.time()\n",
    "mon_dataset[:, 2] = 56 * mon_dataset[:, 3]\n",
    "end = time.time()\n",
    "print(\"10 000 données modifiées en {} secondes\".format(end - start))\n",
    "\n",
    "mon_fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path_root=r'C:\\Users\\Laure\\Brightway - Notebook\\Notebook - tutorial\\IW+ integration\\HDF5 object saved'\n",
    "object_name_to_save=mon_tableau\n",
    "file_name='mon_fichier'\n",
    "\n",
    "pickle_save(file_path_root,object_name_to_save,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mon_fichier = h5py.File(r'C:\\Users\\Laure\\Brightway - Notebook\\Notebook - tutorial\\IW+ integration\\HDF5 object saved\\mon_fichier.hdf5', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_h5py=mon_fichier.get(\"fichier de demo2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset in numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=np.array(dataset_from_h5py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,  56., ...,   1.,   1.,   1.],\n",
       "       [  1.,   1.,  56., ...,   1.,   1.,   1.],\n",
       "       [  1.,   1.,  56., ...,   1.,   1.,   1.],\n",
       "       ..., \n",
       "       [  1.,   1.,  56., ...,   1.,   1.,   1.],\n",
       "       [  1.,   1.,  56., ...,   1.,   1.,   1.],\n",
       "       [  1.,   1.,  56., ...,   1.,   1.,   1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, numpy.ndarray)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array), type(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
